<table class="data-table"><tbody>
<tr>
<th>名称</th>
<th>描述</th>
<th>类型</th>
<th>默认值</th>
<th>有效值</th>
<th>重要性</th>
</tr>
<tr>
<td>zookeeper.connect</td><td>Zookeeper主机地址</td><td>string</td><td></td><td></td><td>高</td></tr>
<tr>
<td>advertised.host.name</td><td>不建议:仅在未设置`advertised.listeners` 或 `listeners`时使用。用`advertised.listeners`替换。
主机名发布到zookeeper供客户端使用。在IaaS环境,这可能需要与broker绑定不通的端口。如果未设置,将使用`host.name`的值（如果已经配置）。否则，他将使用java.net.InetAddress.getCanonicalHostName()返回的值。</td><td>string</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>advertised.listeners</td><td>监听器发布到ZooKeeper供客户端使用，如果与`listeners`配置不同。在IaaS环境,这可能需要与broker绑定不通的接口。如果没有设置，将使用`listeners`的配置。与`listeners`不同的是，配置0.0.0.0元地址是无效的。</td><td>string</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>advertised.port</td><td>不建议:仅在未设置“advertised.listeners”或“listeners”时使用。使用`advertised.listeners`代替。
这个端口发布到ZooKeeper供客户端使用。在IaaS环境，这可能需要与broker绑定不通的端口。如果没有设置，它将绑定和broker相同的端口。</td><td>int</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>auto.create.topics.enable</td><td>是否允许在服务器上自动创建topic</td><td>boolean</td><td>true</td><td></td><td>高</td></tr>
<tr>
<td>auto.leader.rebalance.enable</td><td>是否允许leader平衡。后台线程会定期检查并触发leader平衡。</td><td>boolean</td><td>true</td><td></td><td>高</td></tr>
<tr>
<td>background.threads</td><td>用于处理各种后台任务的线程数量</td><td>int</td><td>10</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>broker.id</td><td>用于服务的broker id。如果没设置，将生存一个唯一broker id。为了避免ZooKeeper生成的id和用户配置的broker id相冲突，生成的id将在reserved.broker.max.id的值基础上加1。</td><td>int</td><td>-1</td><td></td><td>高</td></tr>
<tr>
<td>compression.type</td><td>为特点的topic指定一个最终压缩类型。此配置接受的标准压缩编码方式有（'gzip', 'snappy', 'lz4'）。此外还有'uncompressed'相当于不压缩；'producer'意味着压缩类型由'producer'决定。</td><td>string</td><td>producer</td><td></td><td>高</td></tr>
<tr>
<td>delete.topic.enable</td><td>是否允许删除topic。如果关闭此配置，通过管理工具删除topic将不再生效。</td><td>boolean</td><td>true</td><td></td><td>高</td></tr>
<tr>
<td>host.name</td><td>不建议: 仅在未设置`listeners`时使用。使用`listeners`来代替。
如果设置了broker主机名，则他只会当定到这个地址。如果没设置，将绑定到所有接口。</td><td>string</td><td>""</td><td></td><td>高</td></tr>
<tr>
<td>leader.imbalance.check.interval.seconds</td><td>由控制器触发分区重新平衡检查的频率设置</td><td>long</td><td>300</td><td></td><td>高</td></tr>
<tr>
<td>leader.imbalance.per.broker.percentage</td><td>每个broker允许的不平衡的leader的百分比，如果高于这个比值将触发leader进行平衡。这个值用百分比来指定。</td><td>int</td><td>10</td><td></td><td>高</td></tr>
<tr>
<td>listeners</td><td>监听器列表 - 使用逗号分隔URI列表和监听器名称。如果侦听器名称不是安全协议，则还必须设置listener.security.protocol.map。指定主机名为0.0.0.0来绑定到所有接口。留空则绑定到默认接口上。合法监听器列表的示例：PLAINTEXT：// myhost：9092，SSL：//：9091 CLIENT：//0.0.0.0：9092，REPLICATION：// localhost：9093</td><td>string</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.dir</td><td>保存日志数据的目录（对log.dirs属性的补充）</td><td>string</td><td>/tmp/kafka-logs</td><td></td><td>高</td></tr>
<tr>
<td>log.dirs</td><td>保存日志数据的目录，如果未设置将使用log.dir的配置。</td><td>string</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.flush.interval.messages</td><td>在将消息刷新到磁盘之前，在日志分区上累积的消息数量。</td><td>long</td><td>9223372036854775807</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>log.flush.interval.ms</td><td>在刷新到磁盘之前，任何topic中的消息保留在内存中的最长时间（以毫秒为单位）。如果未设置，则使用log.flush.scheduler.interval.ms中的值。</td><td>long</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.flush.offset.checkpoint.interval.ms</td><td>日志恢复点的最后一次持久化刷新记录的频率</td><td>int</td><td>60000</td><td>[0,...]</td><td>高</td></tr>
<tr>
<td>log.flush.scheduler.interval.ms</td><td>日志刷新器检查是否需要将所有日志刷新到磁盘的频率（以毫秒为单位）</td><td>long</td><td>9223372036854775807</td><td></td><td>高</td></tr>
<tr>
<td>log.flush.start.offset.checkpoint.interval.ms</td><td>我们更新日志持久化记录开始offset的频率</td><td>int</td><td>60000</td><td>[0,...]</td><td>高</td></tr>
<tr>
<td>log.retention.bytes</td><td>日志删除的大小阈值</td><td>long</td><td>-1</td><td></td><td>高</td></tr>
<tr>
<td>log.retention.hours</td><td>日志删除的时间阈值（小时为单位）</td><td>int</td><td>168</td><td></td><td>高</td></tr>
<tr>
<td>log.retention.minutes</td><td>日志删除的时间阈值（分钟为单位），如果未设置，将使用log.retention.hours的值</td><td>int</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.retention.ms</td><td>日志删除的时间阈值（毫秒为单位），如果未设置，将使用log.retention.minutes的值</td><td>long</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.roll.hours</td><td>新日志段轮转时间间隔（小时为单位），次要配置为log.roll.ms</td><td>int</td><td>168</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>log.roll.jitter.hours</td><td>从logrolltimemillis（以小时计）中减去的最大抖动，次要配置log.roll.jitter.ms</td><td>int</td><td>0</td><td>[0,...]</td><td>高</td></tr>
<tr>
<td>log.roll.jitter.ms</td><td>从logrolltimemillis（以毫秒计）中减去的最大抖动，如果未设置，则使用log.roll.jitter.hours的配置</td><td>long</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.roll.ms</td><td>新日志段轮转时间间隔（毫秒为单位），如果未设置，则使用log.roll.hours配置</td><td>long</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>log.segment.bytes</td><td>单个日志段文件最大大小</td><td>int</td><td>1073741824</td><td>[14,...]</td><td>高</td></tr>
<tr>
<td>log.segment.delete.delay.ms</td><td>从文件系统中删除一个日志段文件前的保留时间</td><td>long</td><td>60000</td><td>[0,...]</td><td>高</td></tr>
<tr>
<td>message.max.bytes</td><td><p>kafka允许的最大的一个批次的消息大小。 如果这个数字增加，且有0.10.2版本以下的consumer，那么consumer的提取大小也必须增加，以便他们可以取得这么大的记录批次。
 在最新的消息格式版本中，记录总是被组合到一个批次以提高效率。 在以前的消息格式版本中，未压缩的记录不会分组到批次中，并且此限制仅适用于该情况下的单个记录。</p><p>可以使用topic设置`max.message.bytes`来设置每个topic。 <code>max.message.bytes</code>.</p></td><td>int</td><td>1000012</td><td>[0,...]</td><td>高</td></tr>
<tr>
<td>min.insync.replicas</td><td>当producer将ack设置为“全部”（或“-1”）时，min.insync.replicas指定了被认为写入成功的最小副本数。如果这个最小值不能满足，那么producer将会引发一个异常（NotEnoughReplicas或NotEnoughReplicasAfterAppend）。当一起使用时，min.insync.replicas和acks允许您强制更大的耐久性保证。 一个经典的情况是创建一个复本数为3的topic，将min.insync.replicas设置为2，并且producer使用“all”选项。 这将确保如果大多数副本没有写入producer则抛出异常。</td><td>int</td><td>1</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>num.io.threads</td><td>服务器用于处理请求的线程数，可能包括磁盘I/O</td><td>int</td><td>8</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>num.network.threads</td><td>服务器用于从接收网络请求并发送网络响应的线程数</td><td>int</td><td>3</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>num.recovery.threads.per.data.dir</td><td>每个数据目录，用于启动时日志恢复和关闭时刷新的线程数</td><td>int</td><td>1</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>num.replica.fetchers</td><td>从源broker复制消息的拉取器的线程数。增加这个值可以增加follow broker的I/O并行度。</td><td>int</td><td>1</td><td></td><td>高</td></tr>
<tr>
<td>offset.metadata.max.bytes</td><td>与offset提交相关联的元数据条目的最大大小</td><td>int</td><td>4096</td><td></td><td>高</td></tr>
<tr>
<td>offsets.commit.required.acks</td><td>在offset提交可以接受之前，需要设置acks的数目，一般不需要更改，默认值为-1。</td><td>short</td><td>-1</td><td></td><td>高</td></tr>
<tr>
<td>offsets.commit.timeout.ms</td><td>offset提交将延迟到topic所有副本收到提交或超时。这与producer请求超时类似。</td><td>int</td><td>5000</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>offsets.load.buffer.size</td><td>每次从offset段文件往缓存加载时，批量读取的数据大小</td><td>int</td><td>5242880</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>offsets.retention.check.interval.ms</td><td>检查失效offset的频率</td><td>long</td><td>600000</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>offsets.retention.minutes</td><td>超过这个保留期限未提交的offset将被丢弃</td><td>int</td><td>1440</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>offsets.topic.compression.codec</td><td>用于offsets topic的压缩编解码器 - 压缩可用于实现“原子”提交</td><td>int</td><td>0</td><td></td><td>高</td></tr>
<tr>
<td>offsets.topic.num.partitions</td><td>Offsets topic的分区数量（部署后不应更改）</td><td>int</td><td>50</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>offsets.topic.replication.factor</td><td>offset topic的副本数（设置的越大，可用性越高）。内部topic创建将失败，直到集群大小满足此副本数要求。</td><td>short</td><td>3</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>offsets.topic.segment.bytes</td><td>为了便于更快的日志压缩和缓存加载，offset topic段字节应该保持相对较小</td><td>int</td><td>104857600</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>port</td><td>不建议: 仅在未设置“listener”时使用。使用`listeners`来代替。端口用来来监听和接受连接</td><td>int</td><td>9092</td><td></td><td>高</td></tr>
<tr>
<td>queued.max.requests</td><td>网络线程阻塞前队列允许的最大请求数</td><td>int</td><td>500</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>quota.consumer.default</td><td>不建议:仅在动态默认配额未配置或在zookeeper中使用。任何由clientid区分开来的consumer，如果它每秒产生的字节数多于这个值，就会受到限制</td><td>long</td><td>9223372036854775807</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>quota.producer.default</td><td>不建议:仅在动态默认配额未配置或在zookeeper中使用。任何由clientid区分开来的producer，如果它每秒产生的字节数多于这个值，就会受到限制</td><td>long</td><td>9223372036854775807</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>replica.fetch.min.bytes</td><td>复制数据过程中，replica收到的每个fetch响应，期望的最小的字节数，如果没有收到足够的字节数，就会等待更多的数据，直到达到replicaMaxWaitTimeMs（复制数据超时时间）</td><td>int</td><td>1</td><td></td><td>高</td></tr>
<tr>
<td>replica.fetch.wait.max.ms</td><td>副本follow同leader之间通信的最大等待时间，失败了会重试。 此值始终应始终小于replica.lag.time.max.ms，以防止针对低吞吐量topic频繁收缩ISR</td><td>int</td><td>500</td><td></td><td>高</td></tr>
<tr>
<td>replica.high.watermark.checkpoint.interval.ms</td><td>high watermark被保存到磁盘的频率，用来标记日后恢复点/td><td>long</td><td>5000</td><td></td><td>高</td></tr>
<tr>
<td>replica.lag.time.max.ms</td><td>如果一个follower在这个时间内没有发送fetch请求或消费leader日志到结束的offset，leader将从ISR中移除这个follower，并认为这个follower已经挂了</td><td>long</td><td>10000</td><td></td><td>高</td></tr>
<tr>
<td>replica.socket.receive.buffer.bytes</td><td>socket接收网络请求的缓存大小</td><td>int</td><td>65536</td><td></td><td>高</td></tr>
<tr>
<td>replica.socket.timeout.ms</td><td>副本复制数据过程中，发送网络请求的socket超时时间。这个值应该大于replica.fetch.wait.max.ms的值</td><td>int</td><td>30000</td><td></td><td>高</td></tr>
<tr>
<td>request.timeout.ms</td><td>该配置控制客户端等待请求响应的最长时间。如果在超时之前未收到响应，则客户端将在必要时重新发送请求，如果重试仍然失败，则请求失败。</td><td>int</td><td>30000</td><td></td><td>高</td></tr>
<tr>
<td>socket.receive.buffer.bytes</td><td>服务端用来处理socket连接的SO_RCVBUFF缓冲大小。如果值为-1，则使用系统默认值。</td><td>int</td><td>102400</td><td></td><td>高</td></tr>
<tr>
<td>socket.request.max.bytes</td><td>socket请求的最大大小，这是为了防止server跑光内存，不能大于Java堆的大小。</td><td>int</td><td>104857600</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>socket.send.buffer.bytes</td><td>服务端用来处理socket连接的SO_SNDBUF缓冲大小。如果值为-1，则使用系统默认值。</td><td>int</td><td>102400</td><td></td><td>高</td></tr>
<tr>
<td>transaction.max.timeout.ms</td><td>事务允许的最大超时时间。如果客户请求的事务超时，那么broker将在InitProducerIdRequest中返回一错误。 这样可以防止客户超时时间过长，从而阻碍consumers读取事务中包含的topic。</td><td>int</td><td>900000</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>transaction.state.log.load.buffer.size</td><td>将producer ID和事务加载到高速缓存中时，从事务日志段（the transaction log segments）中批量读取的大小。</td><td>int</td><td>5242880</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>transaction.state.log.min.isr</td><td>覆盖事务topic的min.insync.replicas配置</td><td>int</td><td>2</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>transaction.state.log.num.partitions</td><td>事务topic的分区数（部署后不应该修改）</td><td>int</td><td>50</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>transaction.state.log.replication.factor</td><td>事务topic的副本数（设置的越大，可用性越高）。内部topic在集群数满足副本数之前，将会一直创建失败。</td><td>short</td><td>3</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>transaction.state.log.segment.bytes</td><td>事务topic段应保持相对较小，以便于更快的日志压缩和缓存负载。</td><td>int</td><td>104857600</td><td>[1,...]</td><td>高</td></tr>
<tr>
 <td>transactional.id.expiration.ms</td><td>事务协调器在未收到任何事务状态更新之前，主动设置producer的事务标识为过期之前将等待的最长时间（以毫秒为单位）</td><td>int</td><td>604800000</td><td>[1,...]</td><td>高</td></tr>
<tr>
<td>unclean.leader.election.enable</td><td>指定副本是否能够不再ISR中被选举为leader，即使这样可能会丢数据</td><td>boolean</td><td>false</td><td></td><td>高</td></tr>
<tr>
<td>zookeeper.connection.timeout.ms</td><td>与ZK server建立连接的超时时间,没有配置就使用zookeeper.session.timeout.ms</td><td>int</td><td>null</td><td></td><td>高</td></tr>
<tr>
<td>zookeeper.session.timeout.ms</td><td>ZooKeeper的session的超时时间</td><td>int</td><td>6000</td><td></td><td>高</td></tr>
<tr>
<td>zookeeper.set.acl</td><td>ZooKeeper客户端连接是否设置ACL安全y安装</td><td>boolean</td><td>false</td><td></td><td>高</td></tr>
<tr>
<td>broker.id.generation.enable</td><td>是否允许服务器自动生成broker.id。如果允许则产生的值会交由reserved.broker.max.id审核</td><td>boolean</td><td>true</td><td></td><td>中</td></tr>
<tr>
<td>broker.rack</td><td>broker的机架位置。 这将在机架感知副本分配中用于容错。例如：RACK1，us-east-1</td><td>string</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>connections.max.idle.ms</td><td>连接空闲超时：服务器socket处理线程空闲超时关闭时间</td><td>long</td><td>600000</td><td></td><td>中</td></tr>
<tr>
<td>controlled.shutdown.enable</td><td>是否允许服务器关闭broker服务</td><td>boolean</td><td>true</td><td></td><td>中</td></tr>
<tr>
<td>controlled.shutdown.max.retries</td><td>当发生失败故障时，由于各种原因导致关闭服务的次数</td><td>int</td><td>3</td><td></td><td>中</td></tr>
<tr>
<td>controlled.shutdown.retry.backoff.ms</td><td>在每次重试关闭之前，系统需要时间从上次故障状态（控制器故障切换，副本延迟等）中恢复。
这个配置决定了重试之前等待的时间。</td><td>long</td><td>5000</td><td></td><td>中</td></tr>
<tr>
<td>controller.socket.timeout.ms</td><td>控制器到broker通道的socket超时时间</td><td>int</td><td>30000</td><td></td><td>中</td></tr>
<tr>
<td>default.replication.factor</td><td>自动创建topic时的默认副本个数</td><td>int</td><td>1</td><td></td><td>中</td></tr>
<tr>
<td>delete.records.purgatory.purge.interval.requests</td><td>删除purgatory中请求的清理间隔时间（purgatory：broker对于无法立即处理的请求，将会放在purgatory中，当请求完成后，并不会立即清除，还会继续在purgatory中占用资源，直到下一次delete.records.purgatory.purge.interval.requests）</td><td>int</td><td>1</td><td></td><td>中</td></tr>
<tr>
<td>fetch.purgatory.purge.interval.requests</td><td>提取purgatory中请求的间隔时间</td><td>int</td><td>1000</td><td></td><td>中</td></tr>
<tr>
<td>group.initial.rebalance.delay.ms</td><td>在执行第一次重新平衡之前，group协调器将等待更多consumer加入group的时间。延迟时间越长意味着重新平衡的工作可能越小，但是等待处理开始的时间增加。</td><td>int</td><td>3000</td><td></td><td>中</td></tr>
<tr>
<td>group.max.session.timeout.ms</td><td>consumer注册允许的最大会话超时时间。超时时间越短，处理心跳越频繁从而使故障检测更快，但会导致broker被抢占更多的资源。</td><td>int</td><td>300000</td><td></td><td>medium</td></tr>
<tr>
 <td>group.min.session.timeout.ms</td><td>consumer注册允许的最小会话超时时间。超时时间越短，处理心跳越频繁从而使故障检测更快，但会导致broker被抢占更多的资源。</td><td>int</td><td>6000</td><td></td><td>中</td></tr>
<tr>
<td>inter.broker.listener.name</td><td>broker间通讯的监听器名称。如果未设置，则侦听器名称由security.inter.broker.protocol定义。 同时设置此项和security.inter.broker.protocol属性是错误的，只设置一个。</td><td>string</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>inter.broker.protocol.version</td><td>指定使用哪个版本的 inter-broker 协议。 在所有broker升级到新版本之后，这通常会有冲突。一些有效的例子是：0.8.0, 0.8.1, 0.8.1.1, 0.8.2, 0.8.2.0, 0.8.2.1, 0.9.0.0, 0.9.0.1，详情可以检查apiversion的完整列表</td><td>string</td><td>1.0-IV0</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.backoff.ms</td><td>检查log是否需要清除的时间间隔。</td><td>long</td><td>15000</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>log.cleaner.dedupe.buffer.size</td><td>日志去重清理线程所需要的内存</td><td>long</td><td>134217728</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.delete.retention.ms</td><td>日志记录保留时间</td><td>long</td><td>86400000</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.enable</td><td>在服务器上启用日志清理器进程。如果任何topic都使用cleanup.policy = compact，包括内部topic offset，则建议开启。如果被禁用的话，这些topic将不会被压缩，而且会不断增长。</td><td>boolean</td><td>true</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.io.buffer.load.factor</td><td>日志清理器去重的缓存负载数。完全重复数据的缓存比例可以改变。数值越高，清理的越多，但会导致更多的hash冲突</td><td>double</td><td>0.9</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.io.buffer.size</td><td>所有清理线程的日志清理I/O缓存区所需要的内存</td><td>int</td><td>524288</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>log.cleaner.io.max.bytes.per.second</td><td>日志清理器受到的大小限制数，因此它的I/O读写总和将小于平均值</td><td>double</td><td>1.7976931348623157E308</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.min.cleanable.ratio</td><td>日志中脏数据清理比例</td><td>double</td><td>0.5</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.min.compaction.lag.ms</td><td>消息在日志中保持未压缩的最短时间。
 仅适用于正在压缩的日志。</td><td>long</td><td>0</td><td></td><td>中</td></tr>
<tr>
<td>log.cleaner.threads</td><td>用于日志清理的后台线程的数量</td><td>int</td><td>1</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>log.cleanup.policy</td><td>超出保留窗口期的日志段的默认清理策略。用逗号隔开有效策略列表。有效策略：“delete”和“compact”</td><td>list</td><td>delete</td><td>[compact, delete]</td><td>中</td></tr>
<tr>
<td>log.index.interval.bytes</td><td>添加offset索引字段大小间隔（设置越大，代表扫描速度越快，但是也更耗内存）</td><td>int</td><td>4096</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>log.index.size.max.bytes</td><td>offset索引的最大字节数</td><td>int</td><td>10485760</td><td>[4,...]</td><td>中</td></tr>
<tr>
<td>log.message.format.version</td><td>指定broker用于将消息附加到日志的消息格式版本。应该是一个有效的apiversion值。例如：0.8.2，0.9.0.0，0.10.0，详情去看apiversion。通过设置特定的消息格式版本，用户得保证磁盘上的所有现有消息的版本小于或等于指定的版本。不正确地设置这个值会导致旧版本的用户出错，因为他们将接收到他们无法处理的格式消息。</td><td>string</td><td>1.0-IV0</td><td></td><td>中</td></tr>
<tr>
<td>log.message.timestamp.difference.max.ms</td><td>broker收到消息时的时间戳和消息中指定的时间戳之间允许的最大差异。当log.message.timestamp.type=CreateTime,如果时间差超过这个阈值，消息将被拒绝。如果log.message.timestamp.type = logappendtime，则该配置将被忽略。允许的最大时间戳差值，不应大于log.retention.ms，以避免不必要的频繁日志滚动。</td><td>long</td><td>9223372036854775807</td><td></td><td>中</td></tr>
<tr>
<td>log.message.timestamp.type</td><td>定义消息中的时间戳是消息创建时间还是日志追加时间。
该值应该是“createtime”或“logappendtime”。</td><td>string</td><td>CreateTime</td><td>[CreateTime, LogAppendTime]</td><td>中</td></tr>
<tr>
<td>log.preallocate</td><td>创建新的日志段前是否应该预先分配文件？如果你在windows上使用kafka，你可能需要打开个这个选项</td><td>boolean</td><td>false</td><td></td><td>中</td></tr>
<tr>
<td>log.retention.check.interval.ms</td><td>日志清理器检查是否有日志符合删除的频率（以毫秒为单位）</td><td>long</td><td>300000</td><td>[1,...]</td><td>中</td></tr>
<tr>
<td>max.connections.per.ip</td><td>每个IP允许的最大连接数</td><td>int</td><td>2147483647</td><td>[1,...]</td><td>中</td></tr>
<tr>
<td>max.connections.per.ip.overrides</td><td>每个IP或主机名将覆盖默认的最大连接数</td><td>string</td><td>""</td><td></td><td>中</td></tr>
<tr>
<td>num.partitions</td><td>每个topic的默认日志分区数</td><td>int</td><td>1</td><td>[1,...]</td><td>中</td></tr>
<tr>
<td>principal.builder.class</td><td>实现kafkaprincipalbuilder接口类的全名，该接口用于构建授权期间使用的kafkaprincipal对象。此配置还支持以前已弃用的用于ssl客户端身份验证的principalbuilder接口。如果未定义主体构建器，则默认采用所使用的安全协议。对于ssl身份验证，如果提供了一个主体名称，主体名称将是客户端证书的专有名称;否则，如果不需要客户端身份验证，则主体名称将是匿名的。对于sasl身份验证，如果使用gssapi，则将使用由<code>sasl.kerberos.principal.to.local.rules</code>定义的规则来生成主体，而使用其他机制的sasl身份验证ID。若果用明文，委托人将是匿名的。</td><td>class</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>producer.purgatory.purge.interval.requests</td><td>producer请求purgatory的清除间隔（请求数量）</td><td>int</td><td>1000</td><td></td><td>中</td></tr>
<tr>
<td>queued.max.request.bytes</td><td>在不再读取请求之前队列的字节数</td><td>long</td><td>-1</td><td></td><td>中</td></tr>
<tr>
<td>replica.fetch.backoff.ms</td><td>当拉取分区发生错误时，睡眠的时间。</td><td>int</td><td>1000</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>replica.fetch.max.bytes</td><td>尝试提取每个分区的消息的字节数。这并不是绝对最大值，如果第一个非空分区的第一个批量记录大于这个值，那么批处理仍将被执行并返回，以确保进度可以正常进行下去。broker接受的最大批量记录大小通过<code>message.max.bytes</code>（broker配置）或<code>max.message.bytes</code>（topic配置）进行配置。</td><td>int</td><td>1048576</td><td>[0,...]</td><td>medium</td></tr>
<tr>
<td>replica.fetch.response.max.bytes</td><td>预计整个获取响应的最大字节数。记录被批量取回时，如果取第一个非空分区的第一个批量记录大于此值，记录的批处理仍将被执行并返回以确保可以进行下去。因此，这不是绝对的最大值。
broker接受的最大批量记录大小通过<code>message.max.bytes</code>（broker配置）或<code>max.message.bytes</code>（topic配置）进行配置。</td><td>int</td><td>10485760</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>reserved.broker.max.id</td><td>可以用于broker.id的最大数量</td><td>int</td><td>1000</td><td>[0,...]</td><td>中</td></tr>
<tr>
<td>sasl.enabled.mechanisms</td><td>kafka服务器中启用的sasl机制的列表。
该列表可能包含安全提供程序可用的任何机制。默认情况下只有gssapi是启用的。</td><td>list</td><td>GSSAPI</td><td></td><td>中</td></tr>
<tr>
<td>sasl.kerberos.kinit.cmd</td><td>Kerberos kinit 命令路径。</td><td>string</td><td>/usr/bin/kinit</td><td></td><td>中</td></tr>
<tr>
<td>sasl.kerberos.min.time.before.relogin</td><td>登录线程在尝试刷新间隔内的休眠时间。</td><td>long</td><td>60000</td><td></td><td>中</td></tr>
<tr>
<td>sasl.kerberos.principal.to.local.rules</td><td>主体名称到简称映射的规则列表（通常是操作系统用户名）。按顺序，使用与principal名称匹配的第一个规则将其映射到简称。列表中的任何后续规则都将被忽略。
默认情况下，{username} / {hostname} @ {realm}形式的主体名称映射到{username}。
 有关格式的更多细节，请参阅<a href="#security_authz">安全授权和acls</a>。
请注意，如果由principal.builder.class配置提供了kafkaprincipalbuilder的扩展，则忽略此配置。</td><td>list</td><td>DEFAULT</td><td></td><td>中</td></tr>
<tr>
<td>sasl.kerberos.service.name</td><td>kafka运行的kerberos的主体名称。
这可以在kafka的JAAS配置或在kafka的配置中定义。</td><td>string</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>sasl.kerberos.ticket.renew.jitter</td><td>添加到更新时间的随机抖动的百分比</td><td>double</td><td>0.05</td><td></td><td>中</td></tr>
<tr>
<td>sasl.kerberos.ticket.renew.window.factor</td><td>登录线程将休眠，直到从上次刷新到ticket的到期的时间到达（指定窗口因子），在此期间它将尝试更新ticket。</td><td>double</td><td>0.8</td><td></td><td>中</td></tr>
<tr>
<td>sasl.mechanism.inter.broker.protocol</td><td>SASL机制，用于broker之间的通讯，默认是GSSAPI。</td><td>string</td><td>GSSAPI</td><td></td><td>中</td></tr>
<tr>
<td>security.inter.broker.protocol</td><td>broker之间的安全通讯协议，有效值有：PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL。同时设置此配置和inter.broker.listener.name属性会出错</td><td>string</td><td>PLAINTEXT</td><td></td><td>中</td></tr>
<tr>
<td>ssl.cipher.suites</td><td>密码套件列表。
这是一种用于使用tls或ssl网络协议来协商网络连接的安全设置的认证，加密，mac和密钥交换算法的命名组合。
默认情况下，所有可用的密码套件都受支持。</td><td>list</td><td>null</td><td></td><td>中</td></tr>
<tr>
 <td>ssl.client.auth</td><td>配置请求客户端的broker认证。常见的设置：<ul> <li><code>ssl.client.auth=required</code>如果设置需要客户端认证。<li><code>ssl.client.auth=requested</code>客户端认证可选，不同于requested，客户端可选择不提供自身的身份验证信息。<li><code>ssl.client.auth=none</code> 不需要客户端身份认证。</li></ul></td><td>string</td><td>none</td><td>[required, requested, none]</td><td>中</td></tr>
<tr>
<td>ssl.enabled.protocols</td><td>已启用的SSL连接协议列表。</td><td>list</td><td>TLSv1.2,TLSv1.1,TLSv1</td><td></td><td>中</td></tr>
<tr>
<td>ssl.key.password</td><td>秘钥库文件中的私钥密码。对客户端是可选的。</td><td>password</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>ssl.keymanager.algorithm</td><td>用于SSL连接的密钥管理工厂算法。默认值是为Java虚拟机配置的密钥管理器工厂算法。</td><td>string</td><td>SunX509</td><td></td><td>中</td></tr>
<tr>
<td>ssl.keystore.location</td><td>密钥仓库文件的位置。客户端可选，并可用于客户端的双向认证。</td><td>string</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>ssl.keystore.password</td><td>密钥仓库文件的仓库密码。客户端可选，只有ssl.keystore.location配置了才需要。</td><td>password</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>ssl.keystore.type</td><td>密钥仓库文件的格式。客户端可选。</td><td>string</td><td>JKS</td><td></td><td>中</td></tr>
<tr>
<td>ssl.protocol</td><td>用于生成SSLContext，默认是TLS，适用于大多数情况。允许使用最新的JVM，LS, TLSv1.1 和TLSv1.2。 SSL，SSLv2和SSLv3 老的JVM也可能支持，但由于有已知的安全漏洞，不建议使用。</td><td>string</td><td>TLS</td><td></td><td></td></tr>
<tr>
<td>ssl.provider</td><td>用于SSL连接的安全提供程序的名称。默认值由JVM的安全程序提供。</td><td>string</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>ssl.trustmanager.algorithm</td><td>信任管理工厂用于SSL连接的算法。默认为Java虚拟机配置的信任算法。</td><td>string</td><td>PKIX</td><td></td><td>中</td></tr>
<tr>
<td>ssl.truststore.location</td><td>信任文件的存储位置。 </td><td>string</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>ssl.truststore.password</td><td>信任存储文件的密码。
如果密码未设置，则仍然可以访问信任库，但完整性检查将被禁用。</td><td>password</td><td>null</td><td></td><td>中</td></tr>
<tr>
<td>ssl.truststore.type</td><td>信任存储文件的文件格式。</td><td>string</td><td>JKS</td><td></td><td>中</td></tr>
<tr>
<td>alter.config.policy.class.name</td><td>应该用于验证的alter configs策略类。
该类应该实现org.apache.kafka.server.policy.alterconfigpolicy接口。</td><td>class</td><td>null</td><td></td><td>低</td></tr>
<tr>
<td>authorizer.class.name</td><td>用于认证授权的程序类</td><td>string</td><td>""</td><td></td><td>低</td></tr>
<tr>
<td>create.topic.policy.class.name</td><td>用于验证的创建topic策略类。
该类应该实现org.apache.kafka.server.policy.createtopicpolicy接口。</td><td>class</td><td>null</td><td></td><td>低</td></tr>
<tr>
<td>listener.security.protocol.map</td><td>侦听器名称和安全协议之间的映射。必须定义为相同的安全协议可用于多个端口或IP。例如，即使两者都需要ssl，内部和外部流量也可以分开。具体的说，用户可以定义名字为INTERNAL和EXTERNAL的侦听器，这个属性为：internal：ssl，external：ssl。
如图所示，键和值由冒号分隔，映射条目以逗号分隔。
每个监听者名字只能在映射表上出现一次。
通过向配置名称添加规范化前缀（侦听器名称小写），可以为每个侦听器配置不同的安全性（ssl和sasl）设置。
例如，为内部监听器设置不同的密钥仓库，将会设置名称为“listener.name.internal.ssl.keystore.location”的配置。
如果没有设置侦听器名称的配置，配置将回退到通用配置（即`ssl.keystore.location`）。</td><td>string</td><td>PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</td><td></td><td>低</td></tr>
<tr>
<td>metric.reporters</td><td>度量报告的类列表，通过实现<code>MetricReporter</code>接口，允许插入新度量标准类。JmxReporter包含注册JVM统计。</td><td>list</td><td>""</td><td></td><td>低</td></tr>
<tr>
<td>metrics.num.samples</td><td>维持计算度量的样本数</td><td>int</td><td>2</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>metrics.recording.level</td><td>指标的最高记录级别</td><td>string</td><td>INFO</td><td></td><td>低</td></tr>
<tr>
<td>metrics.sample.window.ms</td><td>计算度量样本的时间窗口</td><td>long</td><td>30000</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>quota.window.num</td><td>在内存中保留客户端限额的样本数</td><td>int</td><td>11</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>quota.window.size.seconds</td><td>每个客户端限额的样本时间跨度</td><td>int</td><td>1</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>replication.quota.window.num</td><td>在内存中保留副本限额的样本数</td><td>int</td><td>11</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>replication.quota.window.size.seconds</td><td>每个副本限额样本数的时间跨度</td><td>int</td><td>1</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>ssl.endpoint.identification.algorithm</td><td>端点身份标识算法，使用服务器证书验证服务器主机名</td><td>string</td><td>null</td><td></td><td>低</td></tr>
<tr>
<td>ssl.secure.random.implementation</td><td>用于SSL加密操作的SecureRandom PRNG实现</td><td>string</td><td>null</td><td></td><td>低</td></tr>
<tr>
<td>transaction.abort.timed.out.transaction.cleanup.interval.ms</td><td>回滚已超时的事务的时间间隔</td><td>int</td><td>60000</td><td>[1,...]</td><td>低</td></tr>
<tr>
<td>transaction.remove.expired.transaction.cleanup.interval.ms</td><td>删除由于transactional.id.expiration.ms传递过程而过期的事务的时间间隔 </td><td>int</td><td>3600000</td><td>[1,...]</td><td>low</td></tr>
<tr>
<td>zookeeper.sync.time.ms</td><td>ZK follower同步可落后leader多久/td><td>int</td><td>2000</td><td></td><td>低</td></tr>
</tbody></table>
